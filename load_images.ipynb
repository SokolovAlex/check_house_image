{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading split 'train' to 'C:\\Users\\alexs\\fiftyone\\open-images-v7\\train' if necessary\n",
      "Necessary images already downloaded\n",
      "Existing download of split 'train' is sufficient\n",
      "Downloading split 'test' to 'C:\\Users\\alexs\\fiftyone\\open-images-v7\\test' if necessary\n",
      "Necessary images already downloaded\n",
      "Existing download of split 'test' is sufficient\n",
      "Downloading split 'validation' to 'C:\\Users\\alexs\\fiftyone\\open-images-v7\\validation' if necessary\n",
      "Necessary images already downloaded\n",
      "Existing download of split 'validation' is sufficient\n",
      "Loading existing dataset 'open-images-v7-130'. To reload from disk, either delete the existing dataset or provide a custom `dataset_name` to use\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"800\"\n",
       "            src=\"http://localhost:5151/?notebook=True&subscription=56186725-4b7a-4dfe-abda-6001eba72f88\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x12a0051d820>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook sessions cannot wait\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision.datasets import ImageFolder\n",
    "import fiftyone.zoo as foz\n",
    "import fiftyone as fo\n",
    "\n",
    "dataset = foz.load_zoo_dataset(\n",
    "    \"open-images-v7\",\n",
    "    label_types=[\"detections\"],\n",
    "    max_samples=130,\n",
    "    classes=[\"House\", \"Building\", \"Cabinetry\", \"Furniture\", \"Desk\", \"Door\", \"Kitchen appliance\"],\n",
    ")\n",
    "\n",
    "session = fo.launch_app(dataset)\n",
    "session.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiftyone as fo\n",
    "\n",
    "session = fo.launch_app(dataset)\n",
    "session.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------->   Compose(\n",
      "    Resize(size=(64, 64), interpolation=bilinear, max_size=None, antialias=True)\n",
      "    ToTensor()\n",
      "    Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OrderedDict([('id', <fiftyone.core.fields.ObjectIdField at 0x12a5fe196a0>),\n",
       "             ('filepath', <fiftyone.core.fields.StringField at 0x12a005fce60>),\n",
       "             ('tags', <fiftyone.core.fields.ListField at 0x12a005fc170>),\n",
       "             ('metadata',\n",
       "              <fiftyone.core.fields.EmbeddedDocumentField at 0x12a5fe19d30>),\n",
       "             ('ground_truth',\n",
       "              <fiftyone.core.fields.EmbeddedDocumentField at 0x12a5fdbb4a0>)])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Преобразование данных для использования в PyTorch\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "print('-------->  ', transform)\n",
    "\n",
    "dataset.get_field_schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 100% |█████████████████| 390/390 [14.8s elapsed, 0s remaining, 13.5 samples/s]      \n"
     ]
    }
   ],
   "source": [
    "dataset.export(\n",
    "    export_dir=\"open_images\",\n",
    "    dataset_type=fo.types.COCODetectionDataset,\n",
    "    label_field=\"ground_truth\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected an image classification exporter and a label field 'ground_truth' of type <class 'fiftyone.core.labels.Detections'>. Exporting image patches...\n",
      " 100% |███████████████| 5066/5066 [2.1m elapsed, 0s remaining, 62.8 samples/s]      \n"
     ]
    }
   ],
   "source": [
    "dataset.export(\n",
    "    export_dir=\"open_images_classification\",\n",
    "    dataset_type=fo.types.ImageClassificationDirectoryTree,\n",
    "    label_field=\"ground_truth\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
